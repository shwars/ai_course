{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En2vX4FuwHlu"
      },
      "source": [
        "## TensorFlow/Keras\n",
        "\n",
        "Мы видели, что для обучения нейросетей нужно:\n",
        "* Быстро умножать матрицы (тензоры)\n",
        "* Считать производные для вычисления градиента для метода обратного распространения ошибки\n",
        "\n",
        "Что позволяют делать нейросетевые фреймворки:\n",
        "* Оперировать с тензорами, как на CPU, так и на GPU\n",
        "* Автоматически вычислять производные (они вручную прописаны для всех элементарных функций)\n",
        "\n",
        "Опционально:\n",
        "* Конструктор для нейросетей (описание сети как набора слоёв)\n",
        "* Простые функции для обучения (`fit`, как в Scikit Learn)\n",
        "* Набор алгоритмов оптимизации\n",
        "* Набор абстракций для работы с данными\n",
        "\n",
        "Основные фреймворки:\n",
        "\n",
        "* Tensorflow 1.0 - первый, получивший широкое распространение (Google). Позволял определять статический computation graph, и затем в явном виде выполнять вычисления\n",
        "* PyTorch - Facebook\n",
        "* Keras - надстройка над Tensorflow/PyTorch для унификации (Francois Chollet)\n",
        "* Tensorflow 2.0 + Keras - динамический вычислительный граф, код получается похожим на обычные вычисления в numpy\n",
        "\n",
        "Мы рассмотрим Tensorflow 2.0 и Keras. Вам необходимо убедиться, что у вас установлена версия 2.x.x Tensorflow:\n",
        "```\n",
        "pip install tensorflow\n",
        "```\n",
        "или\n",
        "```\n",
        "conda install tensorflow\n",
        "```\n",
        "или выполняйте код в [Google Colab](https://colab.research.google.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwqVx9-bwHl3",
        "outputId": "2aa591b4-b647-441f-9c8e-4e0da2d517a0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tp2xGV7wHl4"
      },
      "source": [
        "## Основные понятия в TensorFlow\n",
        "\n",
        "**Тензор** - это многомерный массив произвольной размерности. Удобно использовать при обучении нейросетей, например:\n",
        "* 400x400 - чёрно-белая картинка\n",
        "* 400x400x3 - цветная картинка\n",
        "* 16x400x400x3 - minibatch из 16 картинок, используемый для одного шага обучения\n",
        "* 25x400x400x3 - секунда видео\n",
        "* 8x25x400x400x3 - minibatch из 8 1-секундных видео"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG2bsaR7wHl4"
      },
      "source": [
        "### Простые тензоры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybpnk08HwHl4",
        "outputId": "fad9ed4a-df82-44a0-84ea-324bc71ea46f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "a = tf.constant([[1,2],[3,4]])\n",
        "print(a)\n",
        "a = tf.random.normal(shape=(10,3))\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXFMsV3r09Ux"
      },
      "source": [
        "С тензорами можно производить обычные вычисления, которые производятся поэлементно (как в numpy). При этом тензоры автоматически дополняются до нужной размерности. Можно извлечь numpy-массив из тензора при помощи `.numpy()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5Nu5Xgj1DnQ",
        "outputId": "0dfc8758-4ffd-4968-c7bf-6ba8d435df2e"
      },
      "outputs": [],
      "source": [
        "print(a-a[0])\n",
        "print(tf.exp(a)[0].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ5zN6cVyrG7"
      },
      "source": [
        "### Переменные\n",
        "\n",
        "Переменные могут содержать какие-то значения, которые мы затем можем модифицировать с помощью методов `assign` и `assign_add`. \n",
        "\n",
        "Например, вот глупый способ посчитать сумму всех строк тензора `a`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pu0UZ-_yqfB",
        "outputId": "6708c83e-02e6-4442-8757-45918eb1fbc2"
      },
      "outputs": [],
      "source": [
        "s = tf.Variable(tf.zeros_like(a[0]))\n",
        "for i in a:\n",
        "  s.assign_add(i)\n",
        "\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIh1EHcezlNo"
      },
      "source": [
        "Умный способ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQIdWZ1kzn6P",
        "outputId": "1c123d9a-ecd2-4f2e-828e-5ade85ac8f63"
      },
      "outputs": [],
      "source": [
        "tf.reduce_sum(a,axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-auwezDwHl6"
      },
      "source": [
        "### Вычисляем производные\n",
        "\n",
        "Для обратного распространения ошибки, нам нужно уметь вычислять градиенты. Это делается с помощью `tf.GradientTape()`:\n",
        " * Оборачиваем интересующие нас вычисления в `with tf.GradientTape`\n",
        " * Помечаем интересующие нас тензоры вызовом `tape.watch` (переменные отслеживаются автоматически)\n",
        " * Проводим вычисления\n",
        " * Получаем градиенты через `tape.gradient` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8vFOXr7wHl6",
        "outputId": "860ac72e-50c7-4ff2-f258-747f27194f90",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "a = tf.random.normal(shape=(2, 2))\n",
        "b = tf.random.normal(shape=(2, 2))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(a)  # Start recording the history of operations applied to `a`\n",
        "  c = tf.sqrt(tf.square(a) + tf.square(b))  # Do some math using `a`\n",
        "  # What's the gradient of `c` with respect to `a`?\n",
        "  dc_da = tape.gradient(c, a)\n",
        "  print(dc_da)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sfjBMBu59B5"
      },
      "source": [
        "### Пример 1: Линейная регрессия\n",
        "\n",
        "Попробуем с помощью полученных знаний решить классическую задачу линейной регрессии. Для этого сгенерируем небольшой синтетический датасет:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j723455WwHl7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification, make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "WJNK_J6v6I-Z",
        "outputId": "eb4a66a6-6b9a-4c8a-bc24-d81eeb2d3f27"
      },
      "outputs": [],
      "source": [
        "np.random.seed(13) # pick the seed for reproducability - change it to explore the effects of random variations\n",
        "\n",
        "train_x = np.linspace(0, 3, 120)\n",
        "train_labels = 2 * train_x + 0.9 + np.random.randn(*train_x.shape) * 0.5\n",
        "\n",
        "plt.scatter(train_x,train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng4rZmGc6oxk"
      },
      "source": [
        "Линейная регрессия вычисляется как $f_{W,b}(x) = Wx+b$, где $W, b$ - параметры модели, которые необходимо найти. Функция ошибки на наборе данных $\\{x_i,y_u\\}_{i=1}^N$ может быть определена как среднеевадратичное отклонение\n",
        "$$\n",
        "\\mathcal{L}(W,b) = {1\\over N}\\sum_{i=1}^N (f_{W,b}(x_i)-y_i)^2\n",
        "$$\n",
        "\n",
        "Опишем модель и функцию ошибки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxhI4GlB6aiH"
      },
      "outputs": [],
      "source": [
        "input_dim = 1\n",
        "output_dim = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "# This is our weight matrix\n",
        "w = tf.Variable([[100.0]])\n",
        "# This is our bias vector\n",
        "b = tf.Variable(tf.zeros(shape=(output_dim,)))\n",
        "\n",
        "def f(x):\n",
        "  return tf.matmul(x,w) + b\n",
        "\n",
        "def compute_loss(labels, predictions):\n",
        "  return tf.reduce_mean(tf.square(labels - predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUxwj3367gD2"
      },
      "source": [
        "Обучать модель будем на сериях примеров - minibatches. Для обучения используем градиентный спуск, подстраивая парметры в соответствии с формулой:\n",
        "$$\n",
        "\\begin{array}{l}\n",
        "W^{(n+1)}=W^{(n)}-\\eta\\frac{\\partial\\mathcal{L}}{\\partial W} \\\\\n",
        "b^{(n+1)}=b^{(n)}-\\eta\\frac{\\partial\\mathcal{L}}{\\partial b} \\\\\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-991PErM7fJU"
      },
      "outputs": [],
      "source": [
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = f(x)\n",
        "    loss = compute_loss(y, predictions)\n",
        "    # Note that `tape.gradient` works with a list as well (w, b).\n",
        "    dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
        "  w.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idr2VEWb9rr0"
      },
      "source": [
        "Теперь приступаем к обучению: делаем несколько проходов по всему датасету (эпох), разбиваем его на minibatches, и вызываем функцию обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOuu0qpx-wAp"
      },
      "outputs": [],
      "source": [
        "# Shuffle the data.\n",
        "indices = np.random.permutation(len(train_x))\n",
        "features = tf.constant(train_x[indices],dtype=tf.float32)\n",
        "labels = tf.constant(train_labels[indices],dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zdIf6c_85Ht",
        "outputId": "43b04684-8b90-4c65-d5ff-20ebac61c73c"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "for epoch in range(10):\n",
        "  for i in range(0,len(features),batch_size):\n",
        "    loss = train_on_batch(tf.reshape(features[i:i+batch_size],(-1,1)),tf.reshape(labels[i:i+batch_size],(-1,1)))\n",
        "  print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US6q0nCBD-LL",
        "outputId": "65a79620-a3eb-445b-aafb-60a60575ab0e"
      },
      "outputs": [],
      "source": [
        "w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "_e6xRMZFDnyI",
        "outputId": "d202b7fe-4383-4d82-b98e-a20f3180093e"
      },
      "outputs": [],
      "source": [
        "plt.scatter(train_x,train_labels)\n",
        "x = np.array([min(train_x),max(train_x)])\n",
        "y = w.numpy()[0,0]*x+b.numpy()[0]\n",
        "plt.plot(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0giuwC9GHzi8"
      },
      "source": [
        "### Вычислительный граф\n",
        "\n",
        "Для проведения вычислений Tensorflow строит внутри себя вычислительный граф, который, в т.ч., может вычисляться на GPU. Однако в нашем случае, поскольку мы использовали пользовательские Python-функции, они не включались в вычислительный граф, и при вычислениях на GPU производилась бы передача данных между GPU и CPU и обратно.\n",
        "\n",
        "Для ускорения высчислений и построения единого статического графа, необходимо отметить все функции соответствующим декоратором:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK7HPLz3Hyrl"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = f(x)\n",
        "    loss = compute_loss(y, predictions)\n",
        "    dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
        "  w.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7HusxWkGjLX"
      },
      "source": [
        "### Dataset API\n",
        "\n",
        "Для работы с данными в Tensorflow присутствует удобное API, которым мы в данном случае можем воспользоваться:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYro9Lbr8q0M",
        "outputId": "78c0a6de-71bd-4eef-8819-439495b28672"
      },
      "outputs": [],
      "source": [
        "w.assign([[10.0]])\n",
        "b.assign([0.0])\n",
        "\n",
        "# Create a tf.data.Dataset object for easy batched iteration\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_x.astype(np.float32), train_labels.astype(np.float32)))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(256)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = train_on_batch(tf.reshape(x,(-1,1)), tf.reshape(y,(-1,1)))\n",
        "  print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A10prCPowHl7"
      },
      "source": [
        "### Пример 2: Классификация\n",
        "\n",
        "Рассмотрим пример двухмерной задачи классификации на 2 класса. Примером такой задачи может быть классификация опухоли на 2 типа - доброкачественная и злокачественная, в зависимости от её размера и возраста.\n",
        "\n",
        "Сгенерируем тестовые данные случайным образом:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0OTPkGpwHl7",
        "scrolled": false,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "np.random.seed(0) # pick the seed for reproducability - change it to explore the effects of random variations\n",
        "\n",
        "n = 100\n",
        "X, Y = make_classification(n_samples = n, n_features=2,\n",
        "                           n_redundant=0, n_informative=2, flip_y=0.0,class_sep=1)\n",
        "X = X.astype(np.float32)\n",
        "Y = Y.astype(np.int32)\n",
        "\n",
        "split = [ 70*n//100, (15+70)*n//100 ]\n",
        "train_x, valid_x, test_x = np.split(X, split)\n",
        "train_labels, valid_labels, test_labels = np.split(Y, split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-_BjSHPwHl8",
        "scrolled": false,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def plot_dataset(features, labels, W=None, b=None):\n",
        "    # prepare the plot\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    ax.set_xlabel('$x_i[0]$ -- (feature 1)')\n",
        "    ax.set_ylabel('$x_i[1]$ -- (feature 2)')\n",
        "    colors = ['r' if l else 'b' for l in labels]\n",
        "    ax.scatter(features[:, 0], features[:, 1], marker='o', c=colors, s=100, alpha = 0.5)\n",
        "    if W is not None:\n",
        "        min_x = min(features[:,0])\n",
        "        max_x = max(features[:,1])\n",
        "        min_y = min(features[:,1])*(1-.1)\n",
        "        max_y = max(features[:,1])*(1+.1)\n",
        "        cx = np.array([min_x,max_x],dtype=np.float32)\n",
        "        cy = (0.5-W[0]*cx-b)/W[1]\n",
        "        ax.plot(cx,cy,'g')\n",
        "        ax.set_ylim(min_y,max_y)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "tq0vFchQwHl8",
        "outputId": "9a5aa6a0-c92f-4d72-9e78-c0f615804bff",
        "scrolled": false,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plot_dataset(train_x, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjPlpf2-wHl8"
      },
      "source": [
        "### Обучение простейшего одноуровневого персептрона вручную\n",
        "\n",
        "Используем возможности tensorflow по вычислению градиента для обучения одноуровневого персептрона.\n",
        "\n",
        "Для начала, задаём архитектуру сети, в которой будет 2 входа и один выход. Соответственно, матрица весов $W$ будет иметь размерность $2\\times1$, а вектор сдвига $b$ -- $1$.\n",
        "\n",
        "Функция обучение будет такая же, как в прошлом примере, но функция ошибки будет представлять собой логистическую функцию ошибки. Для этого нам нужно получить на выходе сети значение **вероятности** класса 1, т.е. необходимо привести выход сети $z$ к диапазону [0,1] с помощью передаточной функции `sigmoid`: $p=\\sigma(z)$.\n",
        "Далее, если для примера с номером класса $y_i\\in\\{0,1\\}$ был получен выход сети $p_i$, то ошибка вычисляется как $\\mathcal{L_i}=-(y_i\\log p_i + (1-y_i)log(1-p_i))$. \n",
        "\n",
        "В Tensorflow оба эти этапа (применение сигмоиды и взятие логистической функции ошибки) делается одним вызовом `sigmoid_cross_entropy_with_logits`. Поскольку мы делаем обучение по минибатчам, то необходимо усреднить ошибку по всем компонентам минибатча с помощью `reduce_mean`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdDxWeCqwHl8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "W = tf.Variable(tf.random.normal(shape=(2,1)))\n",
        "b = tf.Variable(tf.zeros(shape=(1,),dtype=tf.float32))\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "@tf.function\n",
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    z = tf.matmul(x, W) + b\n",
        "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=z))\n",
        "    dloss_dw, dloss_db = tape.gradient(loss, [W, b])\n",
        "  W.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAAgw0h6KzUd"
      },
      "source": [
        "Далее, разбиваем входные данные на минибатчи по 16 элементов, и по-очереди проводим обучение, подстраивая веса $W$ и $b$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfyqjVb2wHl8",
        "outputId": "308850b8-fe17-4cda-ac27-8bcda210f113",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a tf.data.Dataset object for easy batched iteration\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_labels.astype(np.float32)))\n",
        "dataset = dataset.batch(16)\n",
        "\n",
        "for epoch in range(15):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = train_on_batch(tf.reshape(x,(-1,2)), tf.reshape(y,(-1,1)))\n",
        "  print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4_Atvn5K4K9"
      },
      "source": [
        "Для демонстрации того, как сработало обучение, построим граничную прямую $W\\times x + b = 0.5$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "PgRTHttLwHl9",
        "outputId": "e4407e1b-edf5-48e5-fdc2-da28120a3c6b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plot_dataset(train_x,train_labels,W.numpy(),b.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Посмотрим на результат классификации на тестовом датасете:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "oEQswfCGrmHw",
        "outputId": "3cf61882-60e1-4baa-8e51-0c31ea80875c"
      },
      "outputs": [],
      "source": [
        "pred = tf.matmul(valid_x,W)+b\n",
        "fig,ax = plt.subplots(1,2)\n",
        "ax[0].scatter(valid_x[:,0],valid_x[:,1],c=pred[:,0]>0.5)\n",
        "ax[1].scatter(valid_x[:,0],valid_x[:,1],c=valid_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Посчитаем точность:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUjdeIefsIsg",
        "outputId": "f267f505-8ba4-43ef-9ebe-df124c3c05a1"
      },
      "outputs": [],
      "source": [
        "tf.reduce_mean(tf.cast(((pred[:,0]>0.5)==valid_labels),tf.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_95qF9lY2kHp"
      },
      "source": [
        "### Используем оптимизаторы TensorFlow\n",
        "\n",
        "Tensorflow достаточно плотно интегрирован с библиотекой Keras, которая содержит в себе множество полезного. Например, мы можем использовать оптимизаторы, реализующие немного другие алгоритмы обучения, чем градиентный спуск.\n",
        "\n",
        "Изменение весов для градиентного спуска имеет вид:\n",
        "$$\\begin{align}\n",
        "\\Delta W^{(i)} &= \\eta\\frac{\\partial \\mathcal{L}}{\\partial W}\\\\\n",
        "\\Delta b^{(i)} &= \\eta\\frac{\\partial \\mathcal{L}}{\\partial b}\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "В результате на каждом шаге направление градиента может существенно меняться из-за того, что мы рассматриваем новый минибатч. Именно поэтому градиентный спуск называется *стохастическим*.\n",
        "\n",
        "Чтобы сгладить такие изменения, мы можем на каждом шаге сохранять некоторые значения градиентов с прошлого шага, т.е.\n",
        "\n",
        "$$\\begin{align}\n",
        "\\Delta W^{(i)} &= \\beta\\Delta W^{(i-1)} + (1-\\beta)\\eta\\frac{\\partial \\mathcal{L}}{\\partial W}\\\\\n",
        "\\Delta b^{(i)} &= \\beta\\Delta b^{(i)} + (1-\\beta)\\eta\\frac{\\partial \\mathcal{L}}{\\partial b}\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "Такой алгоритм называется **Momentum** Gradient Descent. Сущесвуют и другие алгоритмы оптимизации, такие как **AdaGrad**, **Adam** и др.\n",
        "\n",
        "Также попробуем выводить точность на всех этапах обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ups7nlV22ofp",
        "outputId": "aa4dff06-82b9-4b2f-ca00-33970ea2b989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: last batch loss = 9.0650, acc = 0.1667\n",
            "Epoch 1: last batch loss = 9.0169, acc = 0.1667\n",
            "Epoch 2: last batch loss = 8.9621, acc = 0.1667\n",
            "Epoch 3: last batch loss = 8.9025, acc = 0.3333\n",
            "Epoch 4: last batch loss = 8.8384, acc = 0.3333\n",
            "Epoch 5: last batch loss = 8.7696, acc = 0.3333\n",
            "Epoch 6: last batch loss = 8.6959, acc = 0.3333\n",
            "Epoch 7: last batch loss = 8.6170, acc = 0.5000\n",
            "Epoch 8: last batch loss = 8.5325, acc = 0.5000\n",
            "Epoch 9: last batch loss = 8.4422, acc = 0.3333\n",
            "Epoch 10: last batch loss = 8.3461, acc = 0.3333\n",
            "Epoch 11: last batch loss = 8.2439, acc = 0.3333\n",
            "Epoch 12: last batch loss = 8.1359, acc = 0.3333\n",
            "Epoch 13: last batch loss = 8.0223, acc = 0.3333\n",
            "Epoch 14: last batch loss = 7.9037, acc = 0.3333\n",
            "Epoch 15: last batch loss = 7.7805, acc = 0.3333\n",
            "Epoch 16: last batch loss = 7.6537, acc = 0.3333\n",
            "Epoch 17: last batch loss = 7.5241, acc = 0.3333\n",
            "Epoch 18: last batch loss = 7.3929, acc = 0.5000\n",
            "Epoch 19: last batch loss = 7.2611, acc = 0.5000\n",
            "Epoch 20: last batch loss = 7.1298, acc = 0.5000\n",
            "Epoch 21: last batch loss = 7.0001, acc = 0.8333\n",
            "Epoch 22: last batch loss = 6.8728, acc = 0.8333\n",
            "Epoch 23: last batch loss = 6.7488, acc = 0.8333\n",
            "Epoch 24: last batch loss = 6.6288, acc = 0.8333\n",
            "Epoch 25: last batch loss = 6.5133, acc = 0.8333\n",
            "Epoch 26: last batch loss = 6.4026, acc = 0.8333\n",
            "Epoch 27: last batch loss = 6.2970, acc = 0.8333\n",
            "Epoch 28: last batch loss = 6.1966, acc = 0.8333\n",
            "Epoch 29: last batch loss = 6.1013, acc = 0.8333\n",
            "Epoch 30: last batch loss = 6.0112, acc = 0.8333\n",
            "Epoch 31: last batch loss = 5.9260, acc = 0.8333\n",
            "Epoch 32: last batch loss = 5.8455, acc = 0.8333\n",
            "Epoch 33: last batch loss = 5.7695, acc = 0.8333\n",
            "Epoch 34: last batch loss = 5.6977, acc = 0.8333\n",
            "Epoch 35: last batch loss = 5.6299, acc = 0.8333\n",
            "Epoch 36: last batch loss = 5.5658, acc = 0.8333\n",
            "Epoch 37: last batch loss = 5.5051, acc = 0.8333\n",
            "Epoch 38: last batch loss = 5.4476, acc = 0.8333\n",
            "Epoch 39: last batch loss = 5.3931, acc = 0.8333\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "\n",
        "learning_rate = 0.05\n",
        "\n",
        "W = tf.Variable(tf.random.normal(shape=(2,1)))\n",
        "b = tf.Variable(tf.zeros(shape=(1,),dtype=tf.float32))\n",
        "\n",
        "@tf.function\n",
        "def train_on_batch(x, y):\n",
        "  vars = [W, b]\n",
        "  with tf.GradientTape() as tape:\n",
        "    z = tf.sigmoid(tf.matmul(x, W) + b)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(z,y))\n",
        "    correct_prediction = tf.equal(tf.round(y), tf.round(z))\n",
        "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    grads = tape.gradient(loss, vars)\n",
        "    optimizer.apply_gradients(zip(grads,vars))\n",
        "  return loss,acc\n",
        "\n",
        "for epoch in range(40):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss,acc = train_on_batch(tf.reshape(x,(-1,2)), tf.reshape(y,(-1,1)))\n",
        "  print('Epoch %d: last batch loss = %.4f, acc = %.4f' % (epoch, float(loss),acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvAiaj_JndyP"
      },
      "source": [
        "**Задание 1**: Постройте графики ошибок на обучающей и тестовой выборке в процессе обучения\n",
        "\n",
        "**Задание 2**: Попробуйте решить задачу классификации на датасете MNIST с помощью этого кода. Подсказка: используйте `softmax_crossentropy_with_logits` или `sparse_softmax_cross_entropy_with_logits` в качестве функции ошибки. При этом в первом случае на выход сети необходимо подавать целевые значения в формате *one hot encoding*, а во втором - в виде целочисленного номера класса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "995iCprDrgYQ"
      },
      "source": [
        "## Keras\n",
        "### Deep Learning for Humans\n",
        "\n",
        "* Раньше работал поверх Tensorflow, CNTK или Theano, сейчас включен в состав Tensorflow\n",
        "* Оперирует нейросетями на уровне слоёв\n",
        "* Включает упрощённый \"обучатель\", средства работы с типовыми данными (картинками, ...)\n",
        "* Много готовых примеров\n",
        "* Functional API vs. Sequential API\n",
        "\n",
        "Keras даёт более высокоуровневое API для реализации нейросетей, позволяя определять нейросети как комбинации слоёв и оперировать понятиями \"модель\", \"слой\", \"алгоритм обучения\".\n",
        "\n",
        "Книжка от создателя Keras: [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJWplVfy34Eo",
        "outputId": "9be976f2-4f9a-495c-bddc-a7f9ec30989a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "9/9 [==============================] - 1s 4ms/step - loss: 0.8767 - accuracy: 0.3000\n",
            "Epoch 2/15\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7286\n",
            "Epoch 3/15\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.9143\n",
            "Epoch 4/15\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.9000\n",
            "Epoch 5/15\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8857\n",
            "Epoch 6/15\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.9286\n",
            "Epoch 7/15\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3082 - accuracy: 0.9143\n",
            "Epoch 8/15\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.9143\n",
            "Epoch 9/15\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.9286\n",
            "Epoch 10/15\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2950 - accuracy: 0.9143\n",
            "Epoch 11/15\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2918 - accuracy: 0.9143\n",
            "Epoch 12/15\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2909 - accuracy: 0.9286\n",
            "Epoch 13/15\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2905 - accuracy: 0.9286\n",
            "Epoch 14/15\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2950 - accuracy: 0.9286\n",
            "Epoch 15/15\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2896 - accuracy: 0.9286\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(2,))\n",
        "\n",
        "z = tf.keras.layers.Dense(1,kernel_initializer='glorot_uniform',activation='sigmoid')(inputs)\n",
        "\n",
        "model = tf.keras.models.Model(inputs,z)\n",
        "\n",
        "train_x_norm = train_x-np.min(train_x) / (np.max(train_x)-np.min(train_x))\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(0.1),'binary_crossentropy',['accuracy'])\n",
        "model.summary()\n",
        "h = model.fit(train_x_norm,train_labels,batch_size=8,epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "K2Kf60IrZcqs",
        "outputId": "b60b868d-3562-4715-f5d5-1f9764e45f09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x1c20703f7c0>]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(h.history['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJruFXmb_dur"
      },
      "source": [
        "Выше мы использовали **функциональный** способ задания модели, когда мы сначала описываем входную переменную, затем - происходящие с ней преобразования, и потом определяем объект `Model`.\n",
        "\n",
        "Мы можем также задавать модель как последовательности слоёв с помощью `Sequential`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWc_kSr8_YXt",
        "outputId": "345dbe65-629d-468f-ed75-1d412c966340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 5)                 15        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 21\n",
            "Trainable params: 21\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "9/9 [==============================] - 2s 49ms/step - loss: 0.6823 - accuracy: 0.6571 - val_loss: 0.5901 - val_accuracy: 0.7333\n",
            "Epoch 2/15\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.5311 - accuracy: 0.8000 - val_loss: 0.3238 - val_accuracy: 1.0000\n",
            "Epoch 3/15\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3713 - accuracy: 0.9286 - val_loss: 0.1648 - val_accuracy: 1.0000\n",
            "Epoch 4/15\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3069 - accuracy: 0.9429 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
            "Epoch 5/15\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2809 - accuracy: 0.9286 - val_loss: 0.1006 - val_accuracy: 1.0000\n",
            "Epoch 6/15\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2742 - accuracy: 0.9286 - val_loss: 0.0878 - val_accuracy: 1.0000\n",
            "Epoch 7/15\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.2771 - accuracy: 0.9286 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
            "Epoch 8/15\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.2709 - accuracy: 0.9286 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
            "Epoch 9/15\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.2694 - accuracy: 0.9429 - val_loss: 0.0799 - val_accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.2658 - accuracy: 0.9429 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2652 - accuracy: 0.9429 - val_loss: 0.0854 - val_accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.2656 - accuracy: 0.9286 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.2541 - accuracy: 0.9429 - val_loss: 0.0794 - val_accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.2554 - accuracy: 0.9429 - val_loss: 0.0892 - val_accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.2458 - accuracy: 0.9429 - val_loss: 0.0796 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(5,activation='sigmoid',input_shape=(2,)))\n",
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "test_x_norm = test_x-np.min(train_x) / (np.max(train_x)-np.min(train_x))\n",
        "# это не ошибка, мы нормируем тестовые данные так же, как нормировали обучающие!\n",
        "# (поэтому min и max считаем для обучающих данных)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "h = model.fit(train_x_norm,train_labels,validation_data=(test_x_norm,test_labels),batch_size=8,epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x1c206c39b20>]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(h.history['accuracy'])\n",
        "plt.plot(h.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmHNhUU8bqEX"
      },
      "source": [
        "## Функции ошибки при классификации\n",
        "\n",
        "При использовании Keras для классификации важно правильно указать функцию ошибки и передаточную функцию на последнем слое. Основные правила:\n",
        "* Если у сети один выход, то передаточная функция - сигмоида, если несколько - softmax\n",
        "* Если на ожидаемый выход подается в виде one-hot-encoding, то функция ошибки - cross entropy loss (categorical cross-entropy), если номер класса - sparse categorical cross-entropy, для бинарной классификации с одним выходом - binary cross-entropy (она же log loss)\n",
        "\n",
        "В целом бинарную классификацию можно рассматривать как частный случай мультиклассовой, подавая на выход one hot encoded вектор.\n",
        "\n",
        "| Классификация | Формат входных данных | Передат.функция | Функция ошибки |\n",
        "|---------------|-----------------------|-----------------|----------|\n",
        "| Бинарная      | Вероятность 1-го класса | sigmoid | binary crossentropy |\n",
        "| Бинарная      | One-hot encoding (2 выхода) | softmax | categorical crossentropy |\n",
        "| Мультикласс |  One-hot encoding | softmax | categorical crossentropy |\n",
        "| Мультикласс | Номер класса | softmax | sparse categorical crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX6hqiafwHl9"
      },
      "source": [
        "## Выводы\n",
        "\n",
        "* Tensorflow позволяет более гибко определять структуру графа вычислений, описывать свои функции и конфигурации.\n",
        "* Есть более удобные средства для работы с данными (`td.Data`), со слоями (`tf.layers`)\n",
        "* Для массового использования нейросетей Google рекомендует **Keras**, который позволяет собирать нейросети как конструктор\n",
        "* При этом возможно реализовать свой слой для Keras, и потом использовать его в своих моделях.\n",
        "* Для типовых задач имеет смысл использовать Keras\n",
        "* Также стоит посмотреть на PyTorch, это \"восходящая звезда\"\n",
        "\n",
        "Хороший Notebook про Keras и Tensorflow 2.0 от создателя Keras - [тут](https://t.co/k694J95PI8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ-kWx84bMDH"
      },
      "source": [
        "**Задание 3**: \n",
        "Используйте Keras для обучения классификатора на сети MNIST. При этом:\n",
        "* Обратите внимание, что в keras заложены типовые датасеты, включая MNIST. Для обращения к нему достаточно пары строчек кода (см, например, [тут](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist))\n",
        "* Попробуйте несколько конфигураций сети с несколькими полносвязными слоями, передаточными функциями, и разным количеством нейронов\n",
        "\n",
        "Какой точности вам удалось достичь?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG64NKzawHl-",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "collapsed_sections": [],
      "name": "IntroKerasTF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "livereveal": {
      "start_slideshow_at": "selected"
    },
    "vscode": {
      "interpreter": {
        "hash": "d21c24a7952cc9fa93a33c3da71b373ffe761d6ab0c9cc9b2153e31da51ffb58"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
