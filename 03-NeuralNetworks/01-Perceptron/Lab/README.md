## Лабораторная работа
## Ирисы Фишера

В данной работе мы рассмотрим классический датасет [ирисов Фишера](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0). Этот датасет можно напрямую [загрузить из sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html).

Датасет содержит данные о 150 экземплярах ирисов трех различных видов: ирис щетинистый (Iris setosa), ирис виргинский (Iris virginica) и ирис разноцветный (Iris versicolor).  Для каждого экземпляра известен его вид, а также четыре характеристики (в сантиметрах):

* Длина наружной доли околоцветника (англ. sepal length);
* Ширина наружной доли околоцветника (англ. sepal width);
* Длина внутренней доли околоцветника (англ. petal length);
* Ширина внутренней доли околоцветника (англ. petal width).

Необходимо построить классификатор, определяющий тип ириса по измерениям.

> Для этого датасета известно, что один из классов (Iris Setosa) является линейно разделимым от двух остальных, в то время как два других класса имеют более сложную границу.

**Исследование данных**

* Постройте попарные зависимости между всеми входными признаками. Рекомендуется использовать для этого библиотеку Seaborn и фунцию `pairplot`, в соответствии [с этой инструкцией](https://pythonpip.ru/osnovy/parnyy-grafik-seaborn-v-python-dlya-vizualizatsii-dannyh). На этих графиках обозначьте классы ирисов.
* Подтвердите гипотезу линейной разделимости одного из классов визуально.

**Обучение персептрона**

* Разбейте данные на обучающую и тестовую выборку таким образом, чтобы в обучающей и тестовой выборке было равное соотношение классов (т.н. *stratified split*)
* Используя разработанный нами на лекции нейросетевой фреймворк, обучите однослойный персептрон для классификации ирисов на три класса. Какой точности удалось достичь?
* Реализуйте [дополнительные передаточные функции](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%B0%D0%BA%D1%82%D0%B8%D0%B2%D0%B0%D1%86%D0%B8%D0%B8), такие, как ReLU и Sigmoid. По ссылке выше содержатся функции и их производные.
* Обучите двухслойный и трехслойный персептроны. Попробуйте использовать различные передаточные функции между слоями, и различное число нейронов в промежуточном слое. Постройте табличку с полученной метрикой точности для каждого из случаев, например:

   &nbsp;   | 5  | 10 | 20 
  ----|----|----|----
  Relu | .. | .. | ..
  Sigmoid | .. | .. | ..
  Tanh | .. | .. | ..

  (Здесь строки соответствуют разным передаточным функциям между слоями, столбцы - различным значениям числа нейронов на промежуточном слое, на пересечении стоят полученные значения точности классификации)

  > Для более стабильных результатов, проведите обучение для каждого из квадратиков по нескольку раз и усредните результаты

* По лучшей из полученных моделей постройте матрицу ошибок
